{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c78d6-a033-447a-9b03-e122daf91f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ab284-4e6b-4ea0-a1e1-f7b761217ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h4>RNN</h4>\n",
    "<img src=\"./rnn.png\" alt=\"rnn\" />\n",
    "<a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#\">Source</a> \n",
    "<p>The RNN uses a feedback loop to store a previous state. This memory can be unrolled into a previous state, current state and next state. RNNs suffer from a vanishing gradient problem</p>\n",
    "<p>Despite the VG problem, the traditional RNN architectures are a basis for solving sequence type tasks</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fb74f67-c79d-4f8e-87de-2a71375d0b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17]]\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677\n",
    "import math\n",
    "\n",
    "seq = list(range(20))\n",
    "print(len(seq))\n",
    "num = math.floor(len(seq)/3)\n",
    "seq[0:num]\n",
    "seqlen=6\n",
    "batches = [seq[x*seqlen:x*seqlen+num] for x in range(3)]\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b832de2d-20b4-4f6a-86dd-d2ef3f568597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "[6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "class MakeBatch:\n",
    "    def __init__(self,batch_size=3, seqlen=6):\n",
    "        self.batch_size=batch_size\n",
    "        self.seqlen = seqlen\n",
    "        self.startValue = 0\n",
    "    def next(self):\n",
    "        data = range(self.startValue , self.startValue + self.seqlen)\n",
    "        self.startValue += self.seqlen\n",
    "        return list(data)\n",
    "\n",
    "g = MakeBatch()\n",
    "print(g.next())\n",
    "print(g.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8c62958-8c61-47d4-abdf-7b286d22ebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#simple python generator example\n",
    "class GenExample:\n",
    "    def __init__(self,seqlen):\n",
    "        self.seqlen=seqlen\n",
    "        self.i = 0\n",
    "    def get_gen(self):\n",
    "        while self.i < (self.seqlen):\n",
    "            yield self.i\n",
    "            self.i+=1\n",
    "        \n",
    "        \n",
    "# lessons 1) cant use a for loop\n",
    "# 2) return a generator object, not the data\n",
    "# 3) the client API is next(gen object)\n",
    "# data pipelines in cloud you have to build APIs as generator objects\n",
    "# cascade gen objects genobj2(genobj1)\n",
    "y = GenExample(5)\n",
    "z = y.get_gen()\n",
    "print(next(z))\n",
    "print(next(z))\n",
    "print(next(z))\n",
    "print(next(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0cddb4ac-c6ad-4415-9509-113f8ea0ca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "[6, 7, 8, 9, 10, 11]\n",
      "[12, 13, 14, 15, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "class GeneratorBatch:\n",
    "    def __init__(self):\n",
    "        self.seqlen=6\n",
    "        self.batch=3\n",
    "        self.idx =0\n",
    "        self.num_batch=0\n",
    "        self.start = 0\n",
    "    def get_gen(self):\n",
    "        while self.num_batch < self.batch:\n",
    "            yield list(range(self.start, self.start+self.seqlen))\n",
    "            self.num_batch += 1\n",
    "            self.start += self.seqlen\n",
    "            \n",
    "g = GeneratorBatch()\n",
    "y = g.get_gen()\n",
    "try:\n",
    "    print(next(y))\n",
    "    print(next(y))\n",
    "    print(next(y))\n",
    "    print(next(y))\n",
    "except StopIteration:\n",
    "    pass \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab6438a9-3fe1-4965-b50e-12eb73d3a913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import unidecode\n",
    "import string\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "TEXT_PORTION_SIZE = 200\n",
    "\n",
    "NUM_ITER = 5000\n",
    "LEARNING_RATE = 0.005\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "print('Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9edce15f-6154-4faf-a366-7a84fb973001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84657\n"
     ]
    }
   ],
   "source": [
    "with open('./covid.txt') as fh:\n",
    "    lines = fh.read()\n",
    "#print(lines)\n",
    "remove_chars = unidecode.unidecode(lines)\n",
    "remove_chars = re.sub(\" +\",\" \", remove_chars)\n",
    "TEXT_LENGTH = len(remove_chars)\n",
    "print(len(remove_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7178cf0b-ed52-48db-a89d-7375b3cbd560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heck with the vaccine provider.\n",
      "\n",
      "If you're traveling away from Madison before your second dose, we encourage you to get your first dose on campus now and obtain a second dose once you reach your new lo\n"
     ]
    }
   ],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "def random_portion(textfile):\n",
    "    start_index = random.randint(0, TEXT_LENGTH-TEXT_PORTION_SIZE)\n",
    "    end_index = start_index + TEXT_PORTION_SIZE + 1\n",
    "    return textfile[start_index:end_index]\n",
    "\n",
    "print(random_portion(remove_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67056192-a831-4aa5-8c26-ec877702824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "def char_to_tensor(text):\n",
    "    lst = [string.printable.index(c) for c in text]\n",
    "    tensor = torch.tensor(lst).long()\n",
    "    return tensor\n",
    "print(char_to_tensor(\"abcDEF\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b84082c5-974f-4d14-8bc5-5eb544a9f021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 94, 24, 27, 94, 21, 10, 29, 14, 27, 94, 24, 15, 94, 26, 30, 10, 27,\n",
       "         10, 23, 29, 18, 23, 14, 94, 10, 23, 13, 94, 34, 24, 30, 27, 94, 37, 10,\n",
       "         13, 16, 14, 27, 94, 37, 10, 13, 16, 14, 94, 18, 23, 13, 18, 12, 10, 29,\n",
       "         14, 28, 94, 63, 11, 30, 18, 21, 13, 18, 23, 16, 94, 10, 12, 12, 14, 28,\n",
       "         28, 94, 16, 27, 10, 23, 29, 14, 13, 75, 63, 96, 54, 14, 14, 94, 29, 17,\n",
       "         14, 94, 56, 23, 18, 31, 14, 27, 28, 18, 29, 34, 94, 43, 14, 10, 21, 29,\n",
       "         17, 94, 54, 14, 27, 31, 18, 12, 14, 28, 94, 32, 14, 11, 28, 18, 29, 14,\n",
       "         94, 15, 24, 27, 94, 22, 24, 27, 14, 94, 18, 23, 15, 24, 27, 22, 10, 29,\n",
       "         18, 24, 23, 94, 10, 11, 24, 30, 29, 94, 26, 30, 10, 27, 10, 23, 29, 18,\n",
       "         23, 14, 94, 10, 23, 13, 94, 18, 28, 24, 21, 10, 29, 18, 24, 23, 75, 96,\n",
       "         96, 58, 17, 18, 21, 14, 94,  1,  4, 94, 13, 10, 34, 28, 94, 18, 28, 94,\n",
       "         29, 17]),\n",
       " tensor([94, 24, 27, 94, 21, 10, 29, 14, 27, 94, 24, 15, 94, 26, 30, 10, 27, 10,\n",
       "         23, 29, 18, 23, 14, 94, 10, 23, 13, 94, 34, 24, 30, 27, 94, 37, 10, 13,\n",
       "         16, 14, 27, 94, 37, 10, 13, 16, 14, 94, 18, 23, 13, 18, 12, 10, 29, 14,\n",
       "         28, 94, 63, 11, 30, 18, 21, 13, 18, 23, 16, 94, 10, 12, 12, 14, 28, 28,\n",
       "         94, 16, 27, 10, 23, 29, 14, 13, 75, 63, 96, 54, 14, 14, 94, 29, 17, 14,\n",
       "         94, 56, 23, 18, 31, 14, 27, 28, 18, 29, 34, 94, 43, 14, 10, 21, 29, 17,\n",
       "         94, 54, 14, 27, 31, 18, 12, 14, 28, 94, 32, 14, 11, 28, 18, 29, 14, 94,\n",
       "         15, 24, 27, 94, 22, 24, 27, 14, 94, 18, 23, 15, 24, 27, 22, 10, 29, 18,\n",
       "         24, 23, 94, 10, 11, 24, 30, 29, 94, 26, 30, 10, 27, 10, 23, 29, 18, 23,\n",
       "         14, 94, 10, 23, 13, 94, 18, 28, 24, 21, 10, 29, 18, 24, 23, 75, 96, 96,\n",
       "         58, 17, 18, 21, 14, 94,  1,  4, 94, 13, 10, 34, 28, 94, 18, 28, 94, 29,\n",
       "         17, 14]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_random_sample(text_file):\n",
    "    text_long = char_to_tensor(random_portion(text_file))\n",
    "    inputs = text_long[:-1]\n",
    "    targets = text_long[1:]\n",
    "    return inputs, targets\n",
    "draw_random_sample(remove_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "287be7f7-ea93-4c8c-9e1f-794fbe347dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL single row RNN\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, embed_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = torch.nn.Embedding(num_embeddings=input_size, embedding_dim=embed_size)\n",
    "        self.rnn = torch.nn.LSTMCell(input_size=embed_size, hidden_size=hidden_size)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, character, hidden, cell_state):\n",
    "        #char=[batch_size, 1]\n",
    "        #batch_size, embedding = 1, embedding\n",
    "        embedded = self.embed(character)\n",
    "        (hidden, cell_state) = self.rnn(embedded, (hidden, cell_state))\n",
    "        # output: [batch_size, output_size] = [1, output]\n",
    "        # hidden: [batch_size, hidden_dim] = [1, hidden_dim]\n",
    "        # cell: [batch_size, hidden] = [1, hidden_dim]\n",
    "        output = self.fc(hidden)\n",
    "        return output, hidden, cell_state\n",
    "    def init_zero_state(self):\n",
    "        init_hidden = torch.zeros(1, self.hidden_size).to(DEVICE)\n",
    "        init_cell = torch.zeros(1, self.hidden_size).to(DEVICE)\n",
    "        return (init_hidden, init_cell)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(len(string.printable), EMBEDDING_DIM, HIDDEN_DIM,len(string.printable))\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38534dde-be57-4a24-9999-9852781a03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "def evaluate(model, prime_str='A', predict_len=100,temperature=100):\n",
    "    ## based on https://github.com/spro/practical-pytorch/\n",
    "    ## blob/master/char-rnn-generation/char-rnn-generation.ipynb\n",
    "    (hidden, cell_state) = model.init_zero_state()\n",
    "    prime_input = \n",
    "    predicted = prime_str\n",
    "\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        inp = prime_input()\n",
    "        _, hidden, cell_state = model()\n",
    "    inp = prime_input[-1].unsqueeze(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
